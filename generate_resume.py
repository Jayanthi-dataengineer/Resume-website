# generate_resume.py
resume_data = {
    "name": "JAYANTHI N",
    "title": "Data Engineer",
    "summary": "Data Engineer with 2 years of experience in designing automated data pipelines, ensuring accurate data processing, and delivering reliable datasets for analytics. Proven ability to optimize processes, maintain data integrity, and support business decisions through effective reporting solutions.",
    "contact": {
        "location": "Chennai, India",
        "phone": "8925743792",
        "email": "jayanthin1728@gmail.com",
        "linkedin": "https://www.linkedin.com/in/your-link",
        "github": "https://github.com/your-username"
    },
    "skills": [
        "AWS (S3, Redshift, EC2, Lambda)",
        "Snowflake (ETL, Optimization, Backup)",
        "Apache Kafka (Streaming, Automation)",
        "Power BI (Dashboards, Reporting)",
        "Python, Pandas, Scikit-learn, SQL"
    ],
    "experience": [
        {
            "role": "Junior Data Engineer",
            "company": "Vimkes Technologies, Chennai",
            "period": "Nov 2023 – Present",
            "details": [
                "Built automated data pipelines on AWS for raw data ingestion, cleansing, and transformation.",
                "Designed Snowflake warehouse solutions for ETL, query optimization, and time zone-based backups.",
                "Implemented real-time streaming with Apache Kafka to eliminate manual entry.",
                "Developed Power BI dashboards for reporting and decision-making."
            ]
        },
        {
            "role": "CRO",
            "company": "Bhrati Airtel, Chennai",
            "period": "Aug 2022 – Oct 2023",
            "details": [
                "Resolved service and account issues with 90%+ customer satisfaction."
            ]
        }
    ],
    "projects": [
        {
            "name": "Laboratory Information Management System (LIMS)",
            "link": "http://limkes.trustingroup.in/",
            "details": [
                "Automated data pipelines on AWS for ingestion, cleansing, and transformation.",
                "Real-time streaming with Apache Kafka.",
                "Snowflake-based ETL and Power BI dashboards."
            ]
        },
        {
            "name": "Predicting Recruitment Candidate Hiring",
            "tools": "Python, Scikit-learn, Pandas, Matplotlib, Seaborn",
            "details": [
                "Gradient Boosting model with 93.67% accuracy.",
                "Performed data cleaning, EDA, and visualizations.",
                "Delivered insights to improve hiring decisions."
            ]
        }
    ],
    "education": "Bachelor of Commerce in General (CGPA: 8.32), Tagore College of Arts & Science, Chennai (2019 – 2022)",
    "certification": "Advanced Certification in Data Analytics [Edu Bridge (IBM Collaboration)]"
}
